\chapter{Climatology production: \diva 4D\label{chap:diva4D}}

\diva can be used to produce climatologies for a given variable in an oceanic basin. In this case \diva 3D tools are used to produce for successive climatological time periods, 3D climatological analyses on the basin. The resulting climatologies are gathered in 4D binary files GHER format and NetCDF.

The working directory to performs 4D-analyses is:\\ 
\directory{diva-x.x.x/JRA4/Climatology}.

\minitoc


\section{Climatology definition}

The climatologies to be produced are first defined by the mean of three files:

\begin{center}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}ll}
\hline
\file{varlist}: & one column file, where each line defines the short name of a variable \\
 &  (see example~\ref{varlistexp}).\\
\file{yearlist}:& one column file, where the lines define the time period of years  over\\
 & which the climatologies (of the variables) are performed \\
 & (see example~\ref{yearlistexp}). \\
\file{monthlist}: & one column file, where the lines define the time period in the year\\
 &  for which the climatologies (of the variables) are performed \\ 
 & (see example~\ref{monthlistexp}). \\
\hline
\end{tabular*}
\end{center}
 

\begin{center}
\begin{exfile}[H] %[htpb]
\begin{footnotesize}
\begin{verbatim}
Temperature
Salinity
\end{verbatim}
\end{footnotesize}
\caption{\file{varlist}}
\label{varlistexp}
\end{exfile}
\end{center}

\begin{center}
\begin{exfile}[H] %[htpb]
\begin{footnotesize}
\begin{verbatim}
19001950
19501980
19802012
\end{verbatim}
\end{footnotesize}
\caption{\file{yearlist}}
\label{yearlistexp}
\end{exfile}
\end{center}
 
\begin{center}
\begin{exfile}[H] %[htpb]
\begin{footnotesize}
\begin{verbatim}
0103
0406
0709
1012
\end{verbatim}
\end{footnotesize}
\caption{\file{monthlist}}
\label{monthlistexp}
\end{exfile}
\end{center}


\begin{center}
\fbox{
\begin{minipage}{0.9\textwidth}
\vspace{.25cm}
\textbf{Convention:} 
\begin{itemize}
\item In \file{yearlist}, each time period must be in an eight digits number such as $yyyyzzzz$ where $yyyy$ is the start year and $zzzz$ the end year time period.
\item  In \file{monthlist}, each time period must be in a four digits number such as $mmnn$ where $mm$ is the start month and $nn$ the last month numbers.
\item In \file{monthlist}, if the first month is greater than the second (ex. 1202), the next year is considered for months after december (ex. 01 and 02).
\end{itemize}
\vspace{.25cm} 
\end{minipage}
}
\end{center}

\section{\diva 4D climatology performance}
%-----------------------------------------

All \diva shell scripts files for climatologies (or 4D-analyses) production are located in \par \directory{diva-4.6.1/JRAx/Climatology}. This directory has its proper subdirectories:
\begin{itemize}
\item[] \directory{input} where input data and files are placed and 
\item[] \directory{output} where \diva outputs are stored.
\end{itemize}

The main shell script file for generating climatologies is \command{divadoall}. The actions that performed when running \command{divadoall} are:

\begin{itemize}
\item Preparation of data files (ODV files without any depth axis and/or containing current -speed and direction- variables). \command{Divadoall} calls \command{divanodepthODV4}, generating new files with the extension ``\_bis.txt'' containing the x and y components of the speed (u\_star and v\_star), as well as a depth axis.
\item Data extraction at selected depth levels.
\item Cleaning of duplicates in the extracted data (\command{divadoall} calls \command{divaduplicatesODV4} if the analysis flag is not zero).
\item Boundary lines/coastline generation (contour files).
\item Advection field generation based on coastlines.
\item Cleaning of the data outside the mesh.
\item Outliers elimination from data sets.
\item Generation of relative length fields.
\item Optimization of the correlation length (for each data set).
\item Optimization of the signal-to-noise ratio (for each data set).
\item Calculation of variable (semi-normed) reference fields.
\item Performance of variable analysis fields using the following options:
\begin{itemize}
\item analysis without option (normal variational analysis),
\item analysis using a reference fields,
\item analysis using advection constraint,
\item analysis with data transformation,
\item analysis using reference fields for each level calculated on bases of mixed data from three  neighbouring levels,
\item analysis using a filtered mean background field: all levels mean are first calculated an vertically filtered before being used 3D analyses.
\end{itemize}
\item Gnuplot plot production.
\item Analysis with detrending method.
\end{itemize}

\centerline{
\begin{tabular}{|l|}
\hline
{\bf Note:} \\All actions performed by \file{divadoall} are prescribed in the file \file{driver} \\
 through flag values (see section \ref{driverflags} and example \ref{driverfile}).\\
\hline
\end{tabular}
}

{\bf Note:}
\begin{itemize}
\item[*] When data extraction is activated in the \file{driver}, the execution is made for all levels found in \file{contour.depth} file provided in the subdirectory \file{input}. It is also taking into account a minimum number of data in a layer with regard to the corresponding flag value given in \file{driver}.
\item[*] When boundary line and coastline generation is activated in the \file{driver}, the execution is made for all levels found in \file{contour.depth} file provided in the subdirectory \directory{input}.
\item[*] When parameter optimisation and/or analysis is activated, the execution is made for the levels between the values chosen for the lower and upper level numbers and takes into account the bound values (maximum and minimum) prescribed in \file{driver}.
\end{itemize}


%\subsubsection{Inputs for actions performed by \file{divadoall}:}

\centerline{\underline{\bf All actions  performed by \file{divadoall} use the input files:}}

\vspace{0.5cm}

\centerline{
\begin{tabular}{|c|l|}
\hline 
\file{varlist} & \\
\file{yearlist} & in \directory{climatology} directory \\
\file{monthlist} & \\
\hline
\file{contour.depth} &  in \directory{climatology/input} directory \\
\hline
\file{param.par} &  in \directory{climatology/input} or in \\
                 & \directory{climatology/input/divaparam} directory \\
\hline
\end{tabular}
}

\section{Input data preparation}
%-------------------------------

\subsection{Data files}

They must be ODV SeaDataNet compliant: https://www.bodc.ac.uk/data/codes\_and\_formats/odv\_format/


\subsection{Inputs for input data preparation actions}

In \diva 4D (or Climatology production) we can use all the tools provided in \diva 3D for input data preparation.
Input data preparation consists in the following actions:

\vspace{-0.5cm}

\begin{itemize}
\item Data set for extraction.
\item Boundary lines and coastlines generation and advection field generation.
\item Data cleaning on mesh, outliers elimination from data sets and generation of Relative Length fields.
\item Parameters optimisation and reference fields generation.
\end{itemize}

%\vspace{-0.5cm}

To perform an action, one has to configure the \file{driver} file and give in the corresponding flag values and run the
\command{godiva} file script (this will launch the \command{divadoall} script and check for possible severe errors). 
The standard output (stdout) and error (sdterr) will be stored in \file{divadoall.log} while the error and warning lines will be found in 
\file{divadoall.severeerrors}, \\ \file{divadoall.errors} and \file{divadoall.warnings}.
For each action, specific inputs are needed:


%\vspace{1.5cm}

\vspace{0.5cm}
\centerline{
\begin{tabular}{|c|l|}
\hline
{\bf Action} & {\bf Inputs} \\
\hline
    &   \\
Data extraction  &  \file{datasource} in \directory{Climatology} \\
                 &  \file{qflist}  in \directory{Climatology} \\
    &   \\
\hline
    &   \\
 Coastline generation & \file{topogebco.asc}, \file{topo.gebco} or \file{topo.dat} ascii \\
 and ``Advection''     & file or \file{topo.grd} GHER binary format file and its \\
  fields generation     &  related \file{TopoInfo.dat} ascii info-file \\
    &   \\
\hline
    &   \\
Data cleaning on mesh,  & \directory{divadata} a directory which contains data set files of the considered \\
 outliers  elimination  and  &  layers, {\directory{divaparam}} a  directory which contains coastlines \\
generation of relative     &  {\file{coast.cont.$100xx$}} files for all considered layers and a \file{param.par} \\
 length fields         &  file in \directory{input} or \directory{input/divaparam} directory \\
    &   \\
\hline
    &   \\
Parameters optimisation &  {\directory{divadata}} directory which contains the data set \\
 ($L$ and $S/N$)        & files of the considered depths {\directory{divaparam}} directory \\
                        & which contains coastlines {\file{coast.cont.$100xx$}} files of\\
                        & the considered basin, and a(template) {\file{param.par}} file  \\
                        & in \directory{input} or \directory{input/divaparam} directory.\\
    &   \\
\hline
    &   \\
Reference fields &  {\directory{divadata}} directory which contains the data set files\\
generation       &  of the considered depths and time periods\\
				 &  {\directory{divaparam}} directory \\
                 &  which contains coastlines {\file{coast.cont.$100xx$}} files of the \\
                 &  considered basin, and a(template) {\file{param.par}} file  in \directory{input} or \\
                 & a {\file{param.par.var.$100xx$}} files  in \directory{input/divaparam} directory.\\
                 & In these \file{param.par} and/or \file{param.$100xx$} files, ireg is automatically forced to 0. \\
    &   \\
\hline
\end{tabular}
}

\vspace{1.5cm}


\subsection{Outputs of input data preparation actions}

Outputs resulting from a \command{divadoall} run for input data preparation actions are placed in the \directory{input} for data sets extraction and in a \directory{newinput} subdirectory for the other actions as shown in the following table:

\vspace{0.5cm}

\vspace{0.5cm}
\centerline{
\begin{tabular}{|c|l|}
\hline
{\bf Action} & {\bf Outputs} \\
\hline
    &   \\
Data extraction  & A subdirectory {\directory{divadata}} is created in \\
                 &  {\directory{input}} directory, and contains all the data sets. \\
    &   \\
\hline
    &   \\
 Coastlines generation &  A {\directory{newinput}} subdirectory which contains:\\
 and ``Advection''     &  a subdirectory \directory{divaparam} with the {\file{coast.cont.$100xx$}} \\
  field generation     & and  a subdirectory \directory{divaUVcons\_all} containing the\\
                       & velocity field files. \\
                       & All these files are also copied to subdirectories of \directory{input}. \\
    &   \\
\hline
    &   \\
Data cleaning on       & \\
 mesh, outliers        &   A {\directory{newinput/divadata}} subdirectory \\
 elimination  and      &   which contains cleaned data sets and  \\
generation of relative &  relative length files if generated. \\
 length fields         & \\
    &   \\
\hline
    &   \\
Parameters optimisation & A {\directory{newinput/divaparam}} subdirectory which contains \\
 ($L$ and $S/N$)        & \file{param.par.var.$100xx$} files and summary files of the \\
                        & optimisation and filtering procedure.\\
    &   \\
\hline
    &   \\
Reference fields & A {\directory{newinput/divarefe}} subdirectory which contains \\
generation       & all generated reference fields \\
    &   \\
\hline
\end{tabular}
}


\vspace{0.5cm}


The shell script file \command{divadocommit}: in order to be able to use the outputs of input data preparation actions, they must be copied to the \directory{input} directory. This can be done by running the sell script file \command{divadocommit}. 

\vspace{0.5cm}
{\bf Note:} \\
\centerline{
\begin{tabular}{|l|}
\hline
\command{divadocommit} replaces input files in \directory{input} directory by the ones \\
found in \directory{newinput} directory assuming that the \file{driver}, \file{varlist},\\
\file{yearlist} and \file{monthlist} files are the ones used by \command{divadoall}\\
to create the \directory{newinput} subdirectory on which  \command{divadocommit} is run.\\
\hline
\end{tabular}
}
\vspace{-0.4cm}
\begin{itemize}
\item[*] When reference fields are generated, they are copied by the script file \command{divadocommit} in a subdirectory \directory{input/divarefe\_all}.
\end{itemize}


\begin{exfile}[H]
\label{ex_driver}
\begin{footnotesize}
\begin{verbatim}
extract flag: 1 do it, 0 do nothing, -1 press coord, -10 pressure+Saunders
1
boundary lines and coastlines generation: 0 nothing, 1: contours, 2: UV, 3: 1+2
1
cleaning data on mesh: 1, 2: RL, 3: both, 4: 1 + outliers elimination, 5: =4+2
4
minimal number of data in a layer. If less, uses data from any month
10
isoptimise 0 nothing, 1 L, 2 SN, 3 both,  negative values filter vertically
0
Minimal L
0.1
Maximal L
1
Minimal SN
0.05
Maximal SN
0.5
2 do reference, 1 do analysis and 0 do nothing
1
lowerlevel number
7
upperlevel number
11
4D netcdf climatology file
0
isplot 0 or 1
1
number of groups for data detrending, 0 if no detrending.
0
\end{verbatim}
\end{footnotesize}
\caption{The \file{driver} file.} 
\label{driverfile}
\end{exfile}


%-----------------------------------------------------------------------------------
%-----------------------------------------------------------------------------------
%-----------------------------------------------------------------------------------

\section{Production of climatologies}

\diva 4D allows the production of climatologies based on simple \diva data analysis or based on \diva analysis using various options as in \diva 3D:

\begin{itemize}
\item relative length ($RL$) files,
\item advection constraint,
\item reference fields and detrending.
\end{itemize}

\vspace{-0.5cm}

{\bf Note:} These options are automatically activated when the appropriate input data are provided.

\vspace{0.5cm}

{\bf \diva 4D for climatology production offers more options to improve the analysis coherence:}

\vspace{-0.5cm}

\begin{itemize}
\item analysis using vertically filtered mean background
\item analysis with data transformation:  $\log$(data)-$\exp$(analysis), $Logit$ and \it{anamorphosis} transformations or a ``user defined'' transformation.
\item analysis using  a reference field for each layer generated on the basis of all data from the two neighbouring layers in addition to the layer data set.
\end{itemize}

\vspace{-0.5cm}

{\bf Note:} These options are activated with a specific flag values in the \file{driver}.\\
{\bf Note:} The  $Logit$ transformation is made to insure analysis values to be in a given range $[a,b]$. The range $[a,b]$ must be prescribed in a file \file{var.logitrange} (see example \ref{ex:logitrange}) and provided in \directory{input/divadata}. If  \file{var.logitrange} is note provided and the $Logit$ transformation is acctivated, \diva will take the data minimum and maximum values as rage values.



\begin{exfile}[htpb]
\begin{footnotesize}
\texttt{ $0$ \\
$10$\\
}
\end{footnotesize}
\caption{Example of file \file{var.logitrange}. \label{ex:logitrange}}
\end{exfile}



\subsection{Inputs for production of climatologies}

\centerline{\underline{\bf{ in \directory{climatology} directory}}}

\vspace{0.5cm}

\centerline{
\begin{tabular}{|c|l|}
\hline 
\file{varlist}   & \\
\file{yearlist}  & input files defining the climatology \\
\file{monthlist} & \\
\hline 
\file{constandrefe} & input file to activate advection \\
                    & constraint and/or reference fields \\
\hline 
\end{tabular}
}

\vspace{0.5cm}

\centerline{\underline{\bf{ in \directory{climatology/input} directory}}}

\vspace{0.5cm}

\centerline{
\begin{tabular}{|c|l|}
\hline 
\file{contour.depth}  & file of depth values (see example \ref{contdepthfile}) \\
\file{param.par}      & file defining the analysis parameters, provided here \\
                      & if not present in \directory{divaparam} \\
\file{NCDFinfo}       & Info file containing metadata for NetCDF files (see example \ref{NCDFinfoexp})\\
\hline
 \directory{divaparam}     & subdirectory containing coastline files \file{coast.cont.$100xx$}\\
                           & and parameters files \file{param.par.var.$100xx$} \\
 \directory{divadata}      &  subdirectory containing data set files \\
                           & \file{var.yyyyzzzz.mmnn.$100xx$}\\
 \directory{divarefe\_all} & subdirectory containing reference field files (see Section~\ref{divarefeuse}) \\
 \directory{divaUVcons\_all} & subdirectory containing advection constraint fields (see Section~\ref{advconstuse}
)\\
\hline
\end{tabular}
}



\begin{center}
\begin{exfile}[H] %[htpb]
\begin{footnotesize}
\begin{verbatim}

 Title string for 3D NetCDF file:
'Diva 3D analysis '
 Reference time for data (if not climatological data)
'months since since xxxx-01-01'
 Time value (if not climatological data)
1200
 Cell_method string:
'time: mean (this month data from all years)'
 Institution name: where the dataset was produced.
'University of Liege, AGO, GHER'
 Production group and e-mail
'Diva group. E-mails : JM.Beckers@ulg.ac.be'
 Source (observation, radiosonde, database, model-generated data,...)
' data_from various sources'
Comment
'This is only for DIVA development and testing work'
Author e-mail address (or contact person to report problems)
'm.ouberdous@ulg.ac.be'

\end{verbatim}
\end{footnotesize}
\caption{\file{NCDFinfo}}
\label{NCDFinfoexp}
\end{exfile}
\end{center}

%\vspace{0.5cm}

\subsection{Advection constraint and reference field files}


To perform \diva 4D analyses with advection constraint and/or using reference fields, the advection constraint and reference field files must be provided in the corresponding subdirectory \directory{divarefe\_all} and \directory{divaUVcon\_all} in \directory{input} directory (see Sections~\ref{divarefeuse} and \ref{advconstuse}).


{\bf Note:} 

\centerline{
\begin{tabular}{|l|}
\hline 
 The naming conventions for advection field and advection constraint field \\
  files is the same as for \diva 3D: advection condtraint files are named as: \\
 \file{UVinfo.var.yyyy.zzzz.mmnn.$1xxxx$},\\
 \file{Uvel.var.yyyy.zzzz.mmnn.$1xxxx$}, \\
 \file{Vvel.var.yyyy.zzzz.mmnn.$1xxxx$}, and  a \file{constraint.dat} file, \\
 and for reference fild files:\\
 \file{var.yyyy.zzzz.mmnn.$1xxxx$.ascii.ref}, \\
\file{var.yyyy.zzzz.mmnn.$1xxxx$.datapoint.ref} and \\
 \file{var.yyyyzzzz.mmnn.$1xxxx$.ref}\\
\hline
\end{tabular}
}

\subsubsection{Using advection constraint and/or reference field }

The advection constraint and/or reference fields usage actions are activated by the corresponding flag values in \file{constandrefe} file.% (see example~\ref{expconsreff}).
The advection constraint option is activated when the corresponding flag value is equal to $1$. 
The use of reference fields option is activated when the corresponding flag value is equal to $1$, in this case a year period  and month period codes must be provided in the corresponding lines.


\begin{center}
\begin{exfile}[H] %[htpb]
\begin{footnotesize}
\begin{verbatim}
# advection flag
0
# reference field flag
1
# variable year code
19002010
# variable month code
0103
\end{verbatim}
\end{footnotesize}
\caption{\file{constandrefe}}
\label{varlistexp2}
\end{exfile}
\end{center}

\begin{tabular}{|l|}
\hline
\hline
\end{tabular}

\textbf{How to use a different reference field for each month period ? }

Just change the parameter ``refsameasmonthlist'' to ``yes'' in the script \file{divadoall} (around line 330). The month code for your reference field
will then be the same as the current month period. Do not forget to set ``refsameasmonthlist'' back to ``no'' after your analyses.

\pagebreak

\subsection{\diva\ 4D climatology production output}

The outputs are placed in \directory{output/3Danalysis/} and are the same as of the \diva 3D, in addition to the climatologies 4D-NetCDF files:

\begin{description}

\item[The 4D analysis files:] in NetCDF\index{NetCDF} and GHER binary format.


\begin{figure}[H]
\centering
\parbox{\textwidth}{
\begin{tabular}{|lcl|} \hline
\file{var.$yyyyzzzz$.4Danl.nc} & or & \file{var.4Danl.nc} ( of all year periods) \\ 
\hline
\end{tabular}
%\end{footnotesize}
}
%\caption{Content of \directory{output/3Danalysis/}}
\end{figure}

{\bf The 4D variable analysis NetCDF file contains the diva analysis of the variable and a set of variable related information fields: relative error and error standard deviation fields, variable masked (using two relative error thresholds) fields, deepest values of the variable field and the related masked fields. It contains also fields of information about data distribution and outliers as well as fields of correlation length and signal-to-noise ratio parameters.} %(see \ref{4Dncfile})

\item[The 3D analysis files:] in NetCDF and GHER binary format.

\begin{figure}[H]
\centering
\parbox{\textwidth}{
%\begin{footnotesize}
\begin{tabular}{|c|} \hline                                             
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.$1yyyy$.anl.nc} \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.$1yyyy$.errorfieldgher.anl} \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.$1yyyy$.fieldgher.anl} \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.$1yyyy$.fieldgher.ref} \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.$1yyyy$.ref.nc}  \\ 
\hline
\end{tabular}
%\end{footnotesize}
}
%\caption{Content of \directory{output/3Danalysis/}}
\end{figure}


\item[A subdirectory \directory{Fields}] containing all the \diva 2D output files for all levels:


\begin{figure}[H]
\centering
\parbox{\textwidth}{
\begin{footnotesize}
\begin{tabular}{|ll|} \hline

\file{GridInfo.dat}                 & \file{var.$yyyyzzzz.mmnn$.$1xxxx$.ref } \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.anl}              & \file{var.$yyyyzzzz.mmnn$.$1xxxx$.ascii.ref } \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.anl.nc}           & \file{var.$yyyyzzzz.mmnn$.$1xxxx$.datapoint.ref} \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.ascii.anl}        & \file{var.$yyyyzzzz.mmnn$.$1xxxx$.ref.nc}        \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.outliersbis}      & \file{var.$yyyyzzzz.mmnn$.$1xxxx$.outliersbis.norm} \\
\file{var.$yyyyzzzz.mmnn$.$1xxxx$.error}            & \\
 \file{var.$yyyyzzzz.mmnn$.$1xxxx$.errorascii}      & \\
 \file{var.$yyyyzzzz.mmnn$.$1xxxx$.valatxyasc.ref}  & \\
 \file{valatxy.var.$yyyyzzzz.mmnn$.$1xxxx$}         & \\
\hline
\end{tabular}
\end{footnotesize}
}
%\caption{Content of \directory{output/3Danalysis/Fields/}}
\end{figure}


\item[A subdirectory \directory{datadetrend}:] it contains trend data set files for all levels \linebreak \file{trends.$i$.dat.var.$yyyyzzzz.mmnn$.$1xxxx$} ($i$ is the group number).


\item[A subdirectory \directory{Meshes}:] it contains the mesh files, so that they can be re-used for other applications.

\item[Log and metadata files:] Two log files and a text metadata file are generated:
%\vspace{-0.5cm}
\begin{itemize}
\item \file{var.Metainfo.txt}: All the information about domain, grid, variable, and run parameters.
\item \file{var.$yyyyzzzz.mmnn$.Fortran.log}: Log file of fortran binaries run.
\item \file{var.$yyyyzzzz.mmnn$.diva3D.log}: Log file of shell scripts execution.
\end{itemize}

\end{description}

\pagebreak 
%\vspace{0.5cm}

\subsection{{\tt driver} file: actions and flag values\label{driverflags}}

All actions performed by \command{divadoall} are prescribed in the file \file{driver} through flag values. In this section all possible actions and corresponding flag values are listed:

\begin{itemize}
\item {\bf Data extraction}: Possible flag values: $0$,$1$,$-1$ and $-10$. If you activate the data extraction (flag value $\neq 0$) in the \file{driver} file, the execution of \command{divadoall} will run the \command{divaselectorODV4} automatically, including interpolation to the levels specified in {\tt contour.depth}. Data will be extracted from the ODV spreadsheat file(s) specified in \file{datasource}. Command \command{divaselectorODV4} will recognises if the data export to ODV file was done with depths (in meters) or it was done with pressure (in dbar) vertical coordinate, you can either choose to map it as if they were meters or apply the \citet{SAUNDERS81} correction. Choose flag $=-1$ to use pressure coordinate and assume they are meters, and flag value $=-10$ to use pressure coordinates and transform to meters by using the Saunders approach.

If there is a \file{qflist} file, the selection with \file{divaselectorODV4} will only use those measurements for which the quality flag is one of those found in the file \file{qflist}. In the absence of \file{qflist} (or if \file{qflist} is empty), no quality flag analysis is done and all data taken.

{\bf Note:} you can specify several ODV4 spreadsheet files as input files, one file name (or full path) per line in \file{datasource} file, {\it they must have the same variables naming convention}. You can also specify different quality flags for each file by adding these values after the file name (separated by a space). At the moment, a maximum of two quality flags per file is admitted. In the absence of quality flag after the file name, \command{Diva} simply uses the values provided in \file{qflist}.

%{\bf Note:} the weight of data is increased to 1.1 if the file name contains ``CTD,PFL,MRB,DRB or ARGO'' and decreased to 0.5 if it contains ``APB,XBT or MBT'', due to differences in the accuracy of these instruments. This default behaviour can be cancelled by setting the flag\_weight to 0 (in \file{divaselectorODV4}). 

{\bf Note:} the files without any depth axis are treated separately by \command{divano\-depthODV4}. The minimum and maximum
instrument depth (metadata) are used to recreate an artificial depth axis which can be used by diva. Please note that, in this case,
each file without depth axis (in datasource) should contain only one location (otherwise, the other ones are not used). 
This script also handles the current direction (CurrDir [deg T]) and speed (CurrSpd [cm/s]) and transforms them
into x-y components (North, East). In this second case, depth axis has to be present. In any case, \command{divanodepthODV4}
can only deal with a maximum of 2 scalar variables (+ current direction and speed). If you need to analyse more than 2 scalar 
variables, you can proceed by steps (just changing the \file{varlist}).

\item {\bf Boundary lines and coastlines generation}: Possible flag values are $0$, $1$, $2$ and $3$. When this action is activated (flag $\geq 1$), you must provide in the \directory{input} directory the files \file{TopoInfo.dat} and  \file{topo.grd} in addition to \file{contour.depth} file.
              \begin{itemize}
                \item[*] $=1$ if contour files are to be generated,
                \item[*] $=2$ if advection constraint (Anisotropic correlation along topography) files are to be generated from  \texttt{topo.grd},
                \item[*] $=3$ if contour files and advection constraint are to be generated.
              \end{itemize}

\item {\bf Cleaning data and Relative Length}: Possible flag values are $0$, $1$, $2$, $3$, $4$ and $5$:
              \begin{itemize}
                \item[*] $=1$ if data files are to be cleaned,
                \item[*] $=2$ if relative length files depending on data coverage are to be generated,
                \item[*] $=3$ if data files are to be cleaned and relative length files depending on data coverage are to be generated.
                \item[*] $=4$ if outliers are to be cleaned from data files.
                \item[*] $=5$ if outliers are to be cleaned from data files and, relative length files depending on data coverage to be generated.
                \item[*] $=6$ if data files are to be cleaned and relative length files depending on depth to be generated.
              \end{itemize}

\item {\bf Minimum number of data in a layer}: Any value from -1 to infinity. If less, uses data from any month.
                \begin{itemize}
                \item[*] $=-1$ if you never want to use other data from other months.
                \end{itemize}
\item {\bf Parameter optimization}: Possible flag values are $0$, $1$, $2$, $3$, $-1$, $-2$, $-3$, $10$, $-10$, $30$ and $-30$:
              \begin{itemize}
                \item[*] $=1$ if correlation length parameters are to be estimated,
                \item[*] $=2$ if signal-to-noise ratio ($S/N$) parameters are to be estimated,
                \item[*] $=-1$ if correlation length parameters are to be estimated and vertically filtered,
                \item[*] $=-2$ if signal-to-noise ratio ($S/N$) parameters are to be estimated and vertically filtered,
                \item[*] $=3$ if both  correlation length and  signal-to-noise ratio parameters are to be estimated,
                \item[*] $=-3$ if both  correlation length and  signal-to-noise ratio parameters are to be estimated and vertically filtered,

                \item[*] $=10$ if correlation length parameters are to be estimated using data mean distance as a minimum,
                \item[*] $=-10$ if correlation length parameters are to be estimated using data mean distance as a minimum and vertically filtered,
                \item[*] $=30$ if both  correlation length and signal-to-noise ratio parameters are to be estimated using data mean distance as a minimum (for $L$),
                \item[*] $=-30$ if both  correlation length and signal-to-noise ratio parameters are to be estimated using data mean distance as a minimum (for $L$), and both parameters vertically filtered.
% and generated relative length fields (for $S/N$)
              \end{itemize}

\item {\bf Analysis}: analysis and reference fields can be performed in different ways:
  \begin{itemize}
  \item  {\bf Perform analysis}: Possible flag values are $1$, $11$, $12$, $13$ and $14$:
              \begin{itemize}
                \item[*] $=1$ if analysis fields of the given variable are to be performed for all the layers between $L_1$ and $L_2$ which are the flag values for lower level number and upper level number in the \file{driver}.
                \item[*] $=11$ if analysis fields of the given variable are to be performed with $\log$(data)-$\exp$(analysis) transformation
                \item[*] $=12$ if analysis fields of the given variable are to be performed with $Logit$ transformation
                \item[*] $=13$ if analysis fields of the given variable are to be performed with \it{anamorphosis} transformation
                \item[*] $=14$ if analysis fields of the given variable are to be performed with user chosen transformation function.
              \end{itemize}
   \item  {\bf Perform reference fields}: Possible flag values are $2$, $21$, $22$, $23$ and $24$:
              \begin{itemize}
                \item[*] $=2$ if semi normed reference fields of the given variables (prescribed in \file{varlist} and for time periods described in \file{yearlist} and \file{monthlist}) are to be performed for all the layers between $L_1$ and $L_2$, which are the flag values for lower level number and upper level number in the \file{driver}.
                \item[*] $=21$ if analysis fields of the given variable are to be performed with $\log$(data)-$\exp$(analysis) transformation
                \item[*] $=22$ if analysis fields of the given variable are to be performed with $Logit$ transformation
                \item[*] $=23$ if reference fields of the given variable are to be performed with \it{anamorphosis} transformation
                \item[*] $=24$ if reference fields of the given variable are to be performed with user chosen transformation function.
              \end{itemize}
  \item  {\bf Adding $100$ to the flag value}:
              \begin{itemize}
               \item[*] $=101$ or $=11x$ allows performing analysis using reference fields for each layer using all data from the two neighbouring layers in addition to the layer data set. Only reference fields are performed
               \item[*] $=102$ or $=12x$ allows performing reference fields for each layer using all data from the two neighbouring layers in addition to the layer data set.
              \end{itemize}
   \end{itemize}
\item {\bf 4D netcdf files generation}: Possible flag values are $0$, $1$ and $11$:
                \begin{itemize}
                \item[*] $=0$ or $1$ If you only want 3D netcdf output files and a 4D netcdf for each year period,
                \item[*] $=11$ If you also want a big 4D netcdf containing all the year period.
                \end{itemize}
\item {\bf Gnuplot plots}: Possible flag values are $0$ and $1$. Activate this action for a quick visualization (and assessment) of the climatology production, {\tt gnuplot} executions can be included in the production process.\par 
There are a few controls you can apply for these gnuplot plots:
\begin{itemize}
\item[*] \file{VAR.bounds}: contains the lower and upper bounds during the plotting for the variable {\tt VAR} (which is one of the variable names found in {\tt varlist}) 
\item[*] \file{VAR.pal}: contains the color palette for the same variable.
\item[*] \file{plotboundingbox.dat}: contains the box for plotting. This is typically used to plot only the region of interest, without overlapping regions with other climatologies (the numerical fields include the overlapping regions, only the plotting is limited with the \file{plotboundingbox.dat} file).
\end{itemize}
{\bf Note}: the gnuplot colorbars use a scale that is actually remapped to the bounds found in {\tt VAR.bound}. Example:
if your colorbar definition goes from 0 to 10 and the {\tt VAR} bounds are from 0 and 100, a value of 50 in the variable analysed will use the color found in the colorbar definition at value 5. To help you designing a specially adapted color bar lets say for salinity, it is therefore a good idea to define the colorbar with the same bounds as those in \file{VAR.bounds}.

{\bf Note}: for adapting the color palette, file \file{gnuplotcolornames} contains a list of pre-existing colors and their hexadecimal codes you can use instead of names.

\item {\bf Detrending} Possible flag values are $0$ and $n$: the action is activated when choosing flag value an integer $n$ $>0$. The chosen value $n$ must be equal or smaller to groups number in data files.\par
{\bf Note}: If you use \command{divadoall} (or \command{divaselectorODV4}) to extract data and create data input files, columns 5, 6 ,7 and 8 contain respectively groups years, months, days and hours (1 for the first year in the selection etc).
\end{itemize}

